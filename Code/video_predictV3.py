import torch
import cv2
import numpy as np
import os
import time
from tqdm import tqdm

# --- 1. C·∫§U H√åNH (CONFIGURATION) ---
# ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n tr·ªè ƒë√∫ng t·ªõi file .pt b·∫°n v·ª´a export
MODEL_PATH = r"E:\DSUnet-drivable_area_segmentation\Experiments\DSUnet_test_20260122_134633\models\dsunet_deploy.pt" 
INPUT_VIDEO = r"E:\DSUnet-drivable_area_segmentation\Data\Video\mixkit-going-down-a-curved-highway-through-a-mountain-range-41576-hd-ready.mp4"
OUTPUT_DIR = r"E:\DSUnet-drivable_area_segmentation\Inference_Result_Waypoints4"

# K√≠ch th∆∞·ªõc model (Kh·ªõp v·ªõi l√∫c train/export)
MODEL_W, MODEL_H = 512, 288

# M√†u s·∫Øc (BGR)
# 0: Background (Kh√¥ng v·∫Ω), 1: Main Lane, 2: Other Lane, 3: Turn Lane
OVERLAY_COLORS = {
    1: [0, 255, 0],   # Green
    2: [0, 0, 255],   # Red
    3: [255, 0, 0]    # Blue
}

PATH_COLORS = {
    1: [255, 0, 255],   # T√≠m (Main)
    2: [0, 255, 255],   # V√†ng (Other)
    3: [0, 165, 255]    # Cam (Turn)
}

# C·∫•u h√¨nh Waypoint (Gi·ªØ nguy√™n)
WAYPOINT_COLOR = (255, 255, 255) 
WAYPOINT_INTERVAL = 10           
ALPHA = 0.5         # ƒê·ªô trong su·ªët overlay
MIN_AREA = 100      # L·ªçc v√πng nhi·ªÖu nh·ªè
SAMPLE_STEP = 10    # B∆∞·ªõc nh·∫£y khi l·∫•y m·∫´u ƒëi·ªÉm

# --- 2. CLASS D·ª∞ ƒêO√ÅN (L OAD .PT MODEL) ---
class LanePredictor:
    def __init__(self, model_path, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        print(f"üîÑ ƒêang t·∫£i model TorchScript: {model_path}")
        
        try:
            # Load model .pt (ƒë√£ bao g·ªìm c·∫£ ki·∫øn tr√∫c v√† weight)
            self.model = torch.jit.load(model_path, map_location=self.device)
            self.model.eval()
            
            # T·ªëi ∆∞u h√≥a cho ph·∫ßn c·ª©ng
            if self.device.type == 'cuda':
                self.model = torch.jit.optimize_for_inference(self.model)
                torch.backends.cudnn.benchmark = True
            
            # Warm-up (ch·∫°y th·ª≠ 1 l·∫ßn ƒë·ªÉ kh·ªüi ƒë·ªông GPU)
            print("üî• Warming up GPU...")
            dummy = torch.zeros((1, MODEL_H, MODEL_W, 3), dtype=torch.uint8).to(self.device)
            with torch.no_grad(): 
                self.model(dummy)
            print("‚úÖ Model s·∫µn s√†ng!")
            
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫£i model: {e}")
            print("   H√£y ƒë·∫£m b·∫£o file .pt t·ªìn t·∫°i v√† ƒë∆∞·ª£c export ƒë√∫ng c√°ch.")
            exit()

    def predict(self, img_bgr):
        # Resize v·ªÅ k√≠ch th∆∞·ªõc model y√™u c·∫ßu
        img_resized = cv2.resize(img_bgr, (MODEL_W, MODEL_H))
        
        # Chuy·ªÉn sang Tensor (H, W, C) -> (1, H, W, C)
        # L∆∞u √Ω: Model Wrapper (.pt) s·∫Ω t·ª± x·ª≠ l√Ω permute v√† normalize b√™n trong
        img_tensor = torch.from_numpy(img_resized).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            probs = self.model(img_tensor) # Output: (1, Num_Classes, H, W)
            
        # L·∫•y class c√≥ x√°c su·∫•t cao nh·∫•t -> (H, W)
        pred_mask = torch.argmax(probs, dim=1).squeeze().cpu().numpy().astype(np.uint8)
        return pred_mask

# --- 3. X·ª¨ L√ù PATH (GI·ªÆ NGUY√äN LOGIC C≈®) ---
def get_poly_points(sample_y, sample_x, scale_x, scale_y, degree=3):
    if len(sample_y) < 4: return None
    try:
        fit = np.polyfit(sample_y, sample_x, degree)
        poly = np.poly1d(fit)
        y_min, y_max = min(sample_y), max(sample_y)
        plot_y = np.linspace(y_min, y_max, num=int(y_max - y_min))
        plot_x = poly(plot_y)
        
        # Scale v·ªÅ k√≠ch th∆∞·ªõc g·ªëc c·ªßa video
        plot_x_scaled = plot_x * scale_x
        plot_y_scaled = plot_y * scale_y
        
        pts_float = np.transpose(np.vstack([plot_x_scaled, plot_y_scaled]))
        return pts_float
    except:
        return None

def process_main_lane(mask_small, scale_x, scale_y):
    # L·∫•y class 1 (Main Lane)
    binary_mask = (mask_small == 1).astype(np.uint8) * 255
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 15)) 
    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
    
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours: return []
    
    # Ch·ªâ l·∫•y v√πng l·ªõn nh·∫•t
    largest_cnt = max(contours, key=cv2.contourArea)
    if cv2.contourArea(largest_cnt) < MIN_AREA * 2: return []
    
    clean_mask = np.zeros_like(binary_mask)
    cv2.drawContours(clean_mask, [largest_cnt], -1, 255, thickness=cv2.FILLED)
    
    sample_x, sample_y = [], []
    x, y, w, h = cv2.boundingRect(largest_cnt)
    
    for r in range(y + h - 1, y, -SAMPLE_STEP):
        row = clean_mask[r, x : x + w]
        indices = np.where(row == 255)[0]
        if len(indices) > 0:
            center_x = x + int(np.mean(indices))
            sample_x.append(center_x)
            sample_y.append(r)
            
    pts = get_poly_points(sample_y, sample_x, scale_x, scale_y, degree=3)
    return [pts] if pts is not None else []

def process_other_lanes(mask_small, cls_id, scale_x, scale_y):
    binary_mask = (mask_small == cls_id).astype(np.uint8) * 255
    kernel = np.ones((3,3), np.uint8)
    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)
    
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary_mask, connectivity=8)
    paths = []
    
    for i in range(1, num_labels):
        area = stats[i, cv2.CC_STAT_AREA]
        if area < MIN_AREA: continue
        
        x, y, w, h = stats[i, cv2.CC_STAT_LEFT], stats[i, cv2.CC_STAT_TOP], stats[i, cv2.CC_STAT_WIDTH], stats[i, cv2.CC_STAT_HEIGHT]
        sample_x, sample_y = [], []
        
        for r in range(y + h - 1, y, -SAMPLE_STEP):
            row_slice = labels[r, x : x + w]
            indices = np.where(row_slice == i)[0]
            if len(indices) > 0:
                sample_x.append(x + int(np.mean(indices)))
                sample_y.append(r)
        
        pts = get_poly_points(sample_y, sample_x, scale_x, scale_y, degree=3)
        if pts is not None: paths.append(pts)
            
    return paths

# --- 4. V·∫º V√Ä HI·ªÇN TH·ªä (GI·ªÆ NGUY√äN WAYPOINT) ---
def draw_final_result(frame, mask_small, all_paths, fps):
    h_orig, w_orig = frame.shape[:2]
    
    # 1. V·∫Ω Overlay (Segmentation Mask)
    mask_large = cv2.resize(mask_small, (w_orig, h_orig), interpolation=cv2.INTER_NEAREST)
    color_mask = np.zeros_like(frame)
    unique_ids = np.unique(mask_small)
    
    for cls_id in unique_ids:
        if cls_id in OVERLAY_COLORS:
            color_mask[mask_large == cls_id] = OVERLAY_COLORS[cls_id]
            
    mask_bool = (mask_large > 0)
    if np.any(mask_bool):
        frame[mask_bool] = cv2.addWeighted(frame[mask_bool], 1-ALPHA, color_mask[mask_bool], ALPHA, 0)
        
    # 2. V·∫Ω Path & Waypoints
    for cls_id, paths_list in all_paths.items():
        color = PATH_COLORS.get(cls_id, [255, 255, 255])
        
        for pts_float in paths_list:
            pts_int = np.array([pts_float], np.int32)
            
            # V·∫Ω ƒë∆∞·ªùng Path
            if cls_id == 1: 
                cv2.polylines(frame, pts_int, isClosed=False, color=(0,0,0), thickness=8) # Vi·ªÅn ƒëen
                cv2.polylines(frame, pts_int, isClosed=False, color=color, thickness=4)
            else: 
                cv2.polylines(frame, pts_int, isClosed=False, color=color, thickness=3)
            
            # --- V·∫º WAYPOINTS (GI·ªÆ NGUY√äN) ---
            # pts_float: (N, 2) -> ƒê·∫£o ng∆∞·ª£c ƒë·ªÉ v·∫Ω t·ª´ g·∫ßn ra xa
            pts_reversed = pts_float[::-1]
            
            for i, pt in enumerate(pts_reversed):
                # Ch·ªâ v·∫Ω m·ªói ƒëi·ªÉm th·ª© N
                if i % WAYPOINT_INTERVAL == 0:
                    center = (int(pt[0]), int(pt[1]))
                    # Ch·∫•m tr√≤n tr·∫Øng + vi·ªÅn ƒëen
                    cv2.circle(frame, center, 4, WAYPOINT_COLOR, -1) 
                    cv2.circle(frame, center, 5, (0,0,0), 1)

    # 3. Hi·ªÉn th·ªã FPS
    cv2.putText(frame, f"FPS: {fps:.1f}", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    return frame

# --- 5. CH∆Ø∆†NG TR√åNH CH√çNH ---
def run():
    print("üöÄ B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán l√†n ƒë∆∞·ªùng...")
    if not os.path.exists(INPUT_VIDEO):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file video: {INPUT_VIDEO}")
        return
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    save_path = os.path.join(OUTPUT_DIR, f"result_{os.path.basename(INPUT_VIDEO)}")
    
    # Kh·ªüi t·∫°o predictor
    predictor = LanePredictor(MODEL_PATH)
    cap = cv2.VideoCapture(INPUT_VIDEO)
    
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps_in = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # T·ªâ l·ªá scale t·ª´ model ra m√†n h√¨nh
    scale_x = width / MODEL_W
    scale_y = height / MODEL_H
    
    out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps_in, (width, height))
    
    prev_time = time.time()
    pbar = tqdm(total=total_frames, desc="Processing")
    
    try:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            
            # 1. D·ª± ƒëo√°n
            mask_small = predictor.predict(frame)
            
            # 2. X·ª≠ l√Ω h·∫≠u k·ª≥ (t√¨m path)
            all_paths = {}
            unique_classes = np.unique(mask_small)
            
            if 1 in unique_classes:
                all_paths[1] = process_main_lane(mask_small, scale_x, scale_y)
            
            for cls_id in [2, 3]:
                if cls_id in unique_classes:
                    all_paths[cls_id] = process_other_lanes(mask_small, cls_id, scale_x, scale_y)
            
            # 3. V·∫Ω k·∫øt qu·∫£
            curr_time = time.time()
            fps_proc = 1 / (curr_time - prev_time + 1e-6)
            prev_time = curr_time
            
            result_frame = draw_final_result(frame, mask_small, all_paths, fps_proc)
            
            # 4. L∆∞u v√† Hi·ªÉn th·ªã
            out.write(result_frame)
            
            # Resize c·ª≠a s·ªï hi·ªÉn th·ªã cho d·ªÖ nh√¨n
            display_frame = cv2.resize(result_frame, (1024, 576))
            cv2.imshow("DSUnet Lane Detection (.pt)", display_frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'): break
            pbar.update(1)
            
    except KeyboardInterrupt:
        print("\n‚õî D·ª´ng b·ªüi ng∆∞·ªùi d√πng.")
    finally:
        cap.release()
        out.release()
        cv2.destroyAllWindows()
        print(f"\n‚úÖ Ho√†n t·∫•t! Video ƒë√£ l∆∞u t·∫°i:\n   {save_path}")

if __name__ == "__main__":
    run()